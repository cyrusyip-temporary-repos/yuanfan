---
title: 用 ParBayesianOptimization 包寻参时使用并行计算的一些迷思
author: yuanfan
date: '2023-03-22'
slug: epoch
categories:
  - R
tags:
  - R
draft: no
---

挖个坑先。

<!--more-->

以前做 XGBoost 寻参时用的方法是网格寻参，执行起来比较慢，最近听说有个 R 包 ParBayesianOptimization 提供的方法寻参比较快，于是装了试试。由于服务器（Linux CentOS7）上面有防火墙，只能离线下载安装 R 包，这个包有个依赖包 nloptr 装起来很麻烦，一直报错。

>configure: error: C++ compiler cannot create executables

由于安装 xgboost 包需要环境支持 C++14标准，对应需要 gcc6.1以上版本，但不知为何安装 nloptr 必须切换更低版本的 gcc。由于 nloptr 包本身是一个开源的非线性优化库NLopt的接口，按照[nloptr 包的介绍](https://cran.r-project.org/web/packages/nloptr/index.html)，需要现在Linux环境中先安装2.7以上版本的NLopt。接下来我搞不定，领导帮忙装好了包，他的原话是：

>安装 nloptr 要用 gcc4.8.5编译一下 R，然后安装，安装成功后再用 gcc6.1.0 编译一下R，然后再编译 ParBayesianOptimization 剩下需要依赖的包就可以成功了。

包子装好了就可以开始瞎折腾了。我对并行和串行的理解是，并行表示多个独立的任务可以同时执行，而串行表示任务之间不独立、执行步骤之间有所依赖。在 xgboost 包的 xgb.cv 函数中有个 nthread 参数，默认1，在允许的范围内，nthread 设得越大，执行越快，这是在单个节点上设置多线程并行，属于隐性并行计算。相对而言，显性并行计算需要纳入多个节点，但同时也要求每个节点都安装了可用的 R 和 R 包，在设置好了主节点和从节点的基础上，要确保主节点能够连接上从节点。关于多线程并行和多节点并行的区别，我问了一下新必应，它的答案是：两者都属于并行计算的范畴，但适用于不同的场景和需求。

>多线程并行：指在同一个进程中，多个线程同时执行不同的任务，利用单个CPU的多核或超线程技术来提高计算效率。多线程并行的优点是数据共享方便，开销较小；缺点是需要考虑线程安全和同步问题，受CPU核数和内存限制。
>
>多节点并行：指在不同的物理机器或虚拟机器上，多个进程同时执行相同或不同的任务，利用网络通信来实现数据交换和协调。多节点并行的优点是可以突破单机资源限制，提高可扩展性；缺点是数据交换成本较高，需要考虑网络延迟和负载均衡问题。

# 多线程并行

按照[ParBayesianOptimization 包的介绍](https://github.com/AnotherSamWilson/ParBayesianOptimization)，使用并行计算要比不使用更快。此包子里面最重要的函数是`bayesOpt()`，需要在其中设置寻参的轮次（Epoch），每轮次执行比较寻找最优参数的函数的次数。

<details>
<summary>查看寻找 XGBoost 超参数的代码</summary>
<pre><code>

```r
library(xgboost)
library(ParBayesianOptimization)

train <- fread('train.csv')
trainlabel <- train[, 'label']
traindata <- train[, -c('label')]

#若要使用xgb.train，需要先将原来的数据转化为矩阵格式
traindata <- as.matrix(traindata)
trainlabel <- as.matrix(trainlabel)

Folds <- list(Fold1 = as.integer(seq(1, nrow(train), by = 3)),
              Fold2 = as.integer(seq(2, nrow(train), by = 3)),
              Fold3 = as.integer(seq(3, nrow(train), by = 3)))

scoringFunction <-
  function(eta,
           max_depth,
           min_child_weight,
           subsample,
           colsample_bytree,
           gamma,
           lambda,
           alpha) {
    dtrain <-
      xgb.DMatrix(traindata, label = trainlabel)
    
    Pars <- list(
      booster = "gbtree",
      objective = "binary:logistic",
      eval_metric = "auc",
      eta = eta,
      max_depth = max_depth,
      min_child_weight = min_child_weight,
      subsample = subsample,
      colsample_bytree = colsample_bytree,
      gamma = gamma,
      lambda = lambda,
      alpha = alpha
    )
    
    xgbcv <- xgb.cv(
      params = Pars,
      data = dtrain,
      nround = 200,
      folds = Folds,
      # nthread = 16,
      prediction = TRUE,
      showsd = TRUE,
      early_stopping_rounds = 8,
      maximize = TRUE,
      verbose = 0,
      nthread = 4 # 设置多线程
    )
    
    return(list(
      Score = max(xgbcv$evaluation_log$test_auc_mean),
      nrounds = xgbcv$best_iteration
    ))
  }

bounds <- list(
  eta = c(0.001, 0.5),
  max_depth = c(2L, 10L),
  min_child_weight = c(2L, 50L),
  subsample = c(0.25, 1),
  colsample_bytree = c(0.25, 1),
  gamma = c(0, 10),
  lambda = c(0, 10),
  alpha = c(0, 10)
)

set.seed(1234)
optObj <- bayesOpt(
  FUN = scoringFunction,
  bounds = bounds,
  initPoints = 32,
  iters.n = 4
)

# 查看寻参过程
optObj$scoreSummary
# 查看寻找到的超参数
getBestPars(optObj)
```

</code></pre>
</details>

在`bayesOpt`函数中，有几个参数需要设定，其中运行轮次（Epoch）的次数为`iters.n/iters.k`。

+ initPoints：表示初始化过程中使用拉丁超立方采样法在给定范围内选择的点的数量。这个我不大懂，个人理解就是设定一个比需要寻找的超参数的数量更大的值。

+ iters.n：表示初始化后运行 FUN （比较寻找最优参数）函数的总次数。

+ iters.k：表示每个轮次（Epoch）中运行FUN （比较寻找最优参数）函数的次数。如果使用并行计算，建议将 iters.k 设置为可用核心数的倍数，必须小于或等于 iters.n。

<details>
<summary>查看设置多线程并行的代码</summary>
<pre><code>

```r
library(ParBayesianOptimization)
# 多线程并行
library(foreach)
library(iterators)
library(parallel)
library(doParallel)

# 检查一下服务器上面的核数
detectCores(logical = F)

# 设定核数，创建一个用于并行计算的节点集群
cl <- makeCluster(4)

# 注册并行后端
registerDoParallel(cl)

# 检查注册并行后端是否生效，设定4核会得到数字4
getDoParWorkers()

# 把要用到的包和全部对象（包括数据）加载到后端
clusterExport(cl, c('Folds', 'train'))
clusterEvalQ(cl, expr = { library(xgboost) })

set.seed(1234)
optObj <- bayesOpt(
  FUN = scoringFunction,
  bounds = bounds,
  initPoints = 10,
  iters.n = 32,
  iters.k = 8,
  parallel = TRUE)

stopCluster(cl)
registerDoSEQ()
```

</code></pre>
</details>

# 并行与不并行的时间比较-并行更慢？

按照该包子作者的介绍，并行比不并行要快，但是我没有得到这个结果，反而是不并行更快一点……在不并行时执行代码，CPU 利用率保持在90%以上。而在设定并行后执行代码，CPU 利用率会直接飚升到100%，虽然服务器上面 CPU 核数是48且只设定并行线程数是4或8。

<details>
<summary>并行与不并行的时间比较的代码</summary>
<pre><code>

```r
library(xgboost)

data(agaricus.train, package = "xgboost")

Folds <- list(Fold1 = as.integer(seq(1, nrow(agaricus.train$data), by = 3)),
Fold2 = as.integer(seq(2, nrow(agaricus.train$data), by = 3)),
Fold3 = as.integer(seq(3, nrow(agaricus.train$data), by = 3)))

scoringFunction <-
  function(max_depth, min_child_weight, subsample) {
    dtrain <-
      xgb.DMatrix(agaricus.train$data, label = agaricus.train$label)
    
    Pars <- list(
      booster = "gbtree",
      eta = 0.001,
      max_depth = max_depth,
      min_child_weight = min_child_weight,
      subsample = subsample,
      objective = "binary:logistic",
      eval_metric = "auc")
    
    xgbcv <- xgb.cv(
      params = Pars,
      data = dtrain,
      nround = 100,
      folds = Folds,
      early_stopping_rounds = 5,
      maximize = TRUE,
      verbose = 0)
    
    return(list(
      Score = max(xgbcv$evaluation_log$test_auc_mean),
      nrounds = xgbcv$best_iteration
    ))
  }

bounds <- list(
  max_depth = c(1L, 5L),
  min_child_weight = c(0, 25),
  subsample = c(0.25, 1)
)

# 设置不使用并行计算
n1 <- 16
k1 <- 1
A <- system.time(
  optObj <- bayesOpt(
    FUN = scoringFunction,
    bounds = bounds,
    initPoints = 4,
    iters.n = n1,
    iters.k = k1,
    parallel = FALSE))

# 设置多线程并行
cl <- makeCluster(4)
registerDoParallel(cl)
clusterExport(cl, c('Folds', 'agaricus.train'))
clusterEvalQ(cl, expr = {
  library(xgboost)
})

n2 <- 16
k2 <- 4
B <- system.time(
  optObj <- bayesOpt(
    FUN = scoringFunction,
    bounds = bounds,
    initPoints = 4,
    iters.n = n2,
    iters.k = k2,
    parallel = TRUE))

stopCluster(cl)
registerDoSEQ()

A
B
```
</code></pre>
</details>

+ 假如寻参函数运行总次数是16，按花费的实际时长（elapsed）看，A < B。
  - A：默认不使用并行计算，每轮次运行1次函数，一共需运行16轮次。
  - B：使用并行计算，线程数设为4，每轮次运行4次函数，一共需运行4轮次。

```
> A
    user   system  elapsed 
4520.928   23.765  221.648 
> B
   user  system elapsed 
  3.686   0.245 289.303 
```

+ A的设定不变，B的设定改为每轮次运行8次函数，一共需运行2轮次。按花费的实际时长（elapsed）看，A < B。

```
> A
    user   system  elapsed 
4520.928   23.765  221.648 
> B
   user  system elapsed 
  2.026   0.335 237.757 
```

+ A的设定不变，B的设定改为每轮次运行16次函数，一共需运行1轮次。按花费的实际时长（elapsed）看，A < B。

```
> A
    user   system  elapsed 
4520.928   23.765  221.648 
> B
   user  system elapsed 
  1.422   0.257 321.035 
```

+ 总次数增加到32，按花费的实际时长（elapsed）看，A < B。
  - A：默认不使用并行计算，每轮次运行1次函数，一共需运行32轮次。
  - B：使用并行计算，线程数设为4，每轮次运行8次函数，一共需运行4轮次。

```
> A
    user   system  elapsed 
8194.374   38.245  396.726 
> B
   user  system elapsed 
  4.153   0.860 457.497 
```

+ 总次数仍为32，将线程数从4提升至8，按花费的实际时长（elapsed）看，A > B。
  - A：默认不使用并行计算，每轮次运行1次函数，一共需运行32轮次。
  - B：使用并行计算，线程数设为8，每轮次运行8次函数，一共需运行4轮次。

```
> A
    user   system  elapsed 
8100.211   41.690  515.498 
> B
   user  system elapsed 
  4.313   0.521 398.943 
```

# 多线程并行与 xgboost 中的 nthread

在上一小节的基础上，我在`xgb.cv()`函数中加上`nthread = 4`，不管寻参时是否设定并行，整体上都变快了。

+ 总次数仍为32，将线程数设为8，按花费的实际时长（elapsed）看，A >> B。
  - A：默认不使用并行计算，每轮次运行1次函数，一共需运行32轮次。
  - B：使用并行计算，线程数设为8，每轮次运行8次函数，一共需运行4轮次。

```
> A
   user  system elapsed 
399.027   2.474 378.816 
> B
   user  system elapsed 
  3.654   0.087  12.319 
```

在上次的基础上，A/B设定不变，将`xgb.cv()`函数中`nthread = 4`改为`nthread = 8`，服务器上总的CPU核数是48。如果不设定寻参时并行，那么训练模型时增加线程数，运行效率变高。但如果训练模型时线程数设为8，寻参时线程数也设为8,8乘以8等于64超过48，运行效率反而降低。

```
> A
   user  system elapsed 
298.579   3.955 256.512 
> B
   user  system elapsed 
  3.905   0.213  28.357 
```

在`xgb.cv()`函数和`bayesOpt()`函数中同时设置多线程是可能会产生冲突，前者是在给定的数据集和参数下训练模型并输出评估指标，后者是在前者的基础上选择一组新的超参数，然后新的超参数会再输入前者进行训练。两者设定的线程数相乘超过总的CPU核数时，反而导致整体运行效率减慢。